{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malaria_Cell_Detection_Using_VGGNet_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joycechidi/Deep-Learning-/blob/master/CNN/Malaria_Cell_Detection_Using_VGGNet_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm9zjYHW4e4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8983266b-0e30-46bb-ea49-ce98ecada010"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOHRV4yv6c6R",
        "colab_type": "text"
      },
      "source": [
        "## Transfer Learning\n",
        "In this notebook, I'll be using VGGNet trained on the ImageNet dataset as a feature extractor. \n",
        "\n",
        "I'm using VGGNet because it's simple and has great performance, coming in second in the ImageNet competition. \n",
        "\n",
        "All the convolutional layers will be kept but I will replace the final fully-connected layer with my own classifier. This way I can use VGGNet as a fixed feature extractor for my images then easily train a simple classifier on top of that.\n",
        "\n",
        "*   Use all but the last fully-connected layer as a fixed feature extractor.\n",
        "*   Define a new, final classification layer and apply it to a task of our choice!\n",
        "\n",
        "I am trying to use the dataset containing infected and uninfected malaria cell images. Downloaded from Kaggle here [https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria/download]\n",
        "\n",
        "### Objective\n",
        "Build a convolutional neural network that can detect the presence of malaria parasite in blood cells.\n",
        "\n",
        "After training this dataset with VGGNet, I will also train with ResNet pre-trained model and then compare the performance between the two models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64i4MNkP6boI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bg4JqSGMMUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(\"/content/gdrive/My Drive/Udacity_AI_Codes/DLND_Works/data/cell_images/cell_images/\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPp8RBhb6bh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be7f06a1-739a-4260-93b6-4d975c092569"
      },
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...') "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMDK79DbRVc3",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9sbQHxMRZNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training and test data directories\n",
        "data_dir = os.path.join(\"/content/gdrive/My Drive/Udacity_AI_Codes/DLND_Works/data/cell_images/cell_images\")\n",
        "train_dir = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
        "#train_dir = os.path.join(data_dir, 'train/')\n",
        "#test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['Uninfected', 'Parasitized']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "355yuhnWIZ1H",
        "colab_type": "text"
      },
      "source": [
        "## Transforming the Data\n",
        "\n",
        "Since I am training this dataset with a pre-trained model, I will have to shape the input data into the shape the pre-trained model expects.\n",
        "\n",
        "VGG16 expects 224-dim square images as input, so I'll resize each cell image to into this mold/shape.\n",
        "\n",
        "### Data Augmentation\n",
        "\n",
        "\n",
        "1.   Resized all images as input to 224 as expected by VGGNet\n",
        "2.   Apply different transformation by rotating the images horizontally and vertically\n",
        "3.   Convert images into PyTorch Tensors\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-pDzHz26bem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and transform data using ImageFolder\n",
        "\n",
        "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
        "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                     transforms.ColorJitter(0.05),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.RandomVerticalFlip(),\n",
        "                                     transforms.RandomRotation(20),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "\n",
        "# print out some data stats\n",
        "print('Num training images: ', len(train_data))\n",
        "print('Num test images: ', len(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQXe85t8LCzE",
        "colab_type": "text"
      },
      "source": [
        "## **DataLoaders and Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-rqk1pJ6bal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define dataloaders parameters\n",
        "batch_size = 100 \n",
        "num_workers = 0\n",
        "\n",
        "#prepare dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqTU_dG96bX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkr7X1bR6bT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxikrtzw6bSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7i0B9d_6bQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lN-DoDd6bO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5EYYtUo6bLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf7LGc486bJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOotThfI6bGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGSsIROR6bDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWaO0TBF6atU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}